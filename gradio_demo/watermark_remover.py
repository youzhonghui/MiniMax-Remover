import os
import gradio as gr
import cv2
import numpy as np
from PIL import Image
import torch
import time
import random
from diffusers.models import AutoencoderKLWan
from transformer_minimax_remover import Transformer3DModel
from diffusers.schedulers import UniPCMultistepScheduler
from pipeline_minimax_remover import Minimax_Remover_Pipeline
from diffusers.utils import export_to_video
from decord import VideoReader, cpu
from moviepy.editor import ImageSequenceClip
from huggingface_hub import snapshot_download

# åˆ›å»ºå¿…è¦çš„ç›®å½•
os.makedirs("./model/", exist_ok=True)

def download_remover():
    """ä¸‹è½½MiniMax-Removeræ¨¡å‹"""
    if not os.path.exists("./model/vae"):
        snapshot_download(repo_id="zibojia/minimax-remover", local_dir="./model/")
        print("Download minimax remover completed")
    else:
        print("Model already exists")

# ä¸‹è½½æ¨¡å‹
download_remover()

# å…¨å±€é…ç½®
random_seed = 42
device = "cuda" if torch.cuda.is_available() else "cpu"

def get_pipeline():
    """åˆå§‹åŒ–MiniMax-Removerç®¡é“"""
    vae = AutoencoderKLWan.from_pretrained("./model/vae", torch_dtype=torch.float16)
    transformer = Transformer3DModel.from_pretrained("./model/transformer", torch_dtype=torch.float16)
    scheduler = UniPCMultistepScheduler.from_pretrained("./model/scheduler")

    pipe = Minimax_Remover_Pipeline(transformer=transformer, vae=vae, scheduler=scheduler)
    pipe.to(device)
    return pipe

def load_video_frames(video_path, max_frames=201):
    """åŠ è½½è§†é¢‘å¸§"""
    try:
        vr = VideoReader(video_path, ctx=cpu(0))
        num_frames = min(len(vr), max_frames)
        frames = [vr[i].asnumpy() for i in range(num_frames)]
        del vr
        return frames, num_frames
    except Exception as e:
        raise gr.Error(f"è§†é¢‘åŠ è½½å¤±è´¥: {str(e)}")

def load_mask_frames(mask_path, target_frames):
    """åŠ è½½è’™ç‰ˆå¸§"""
    try:
        vr = VideoReader(mask_path, ctx=cpu(0))
        if len(vr) < target_frames:
            raise gr.Error(f"è’™ç‰ˆè§†é¢‘å¸§æ•°({len(vr)})å°‘äºç›®æ ‡è§†é¢‘å¸§æ•°({target_frames})")
        
        masks = []
        for i in range(target_frames):
            mask_frame = vr[i].asnumpy()
            # è½¬æ¢ä¸ºç°åº¦è’™ç‰ˆ
            if len(mask_frame.shape) == 3:
                mask_frame = cv2.cvtColor(mask_frame, cv2.COLOR_RGB2GRAY)
            # äºŒå€¼åŒ–è’™ç‰ˆ
            mask_frame = (mask_frame > 127).astype(np.float32)
            masks.append(mask_frame)
        del vr
        return masks
    except Exception as e:
        raise gr.Error(f"è’™ç‰ˆåŠ è½½å¤±è´¥: {str(e)}")

def validate_dimensions(video_frames, mask_frames):
    """éªŒè¯è§†é¢‘å’Œè’™ç‰ˆå°ºå¯¸"""
    if len(video_frames) != len(mask_frames):
        raise gr.Error(f"è§†é¢‘å¸§æ•°({len(video_frames)})ä¸è’™ç‰ˆå¸§æ•°({len(mask_frames)})ä¸åŒ¹é…")
    
    video_shape = video_frames[0].shape[:2]
    mask_shape = mask_frames[0].shape[:2]
    
    if video_shape != mask_shape:
        raise gr.Error(f"è§†é¢‘å°ºå¯¸{video_shape}ä¸è’™ç‰ˆå°ºå¯¸{mask_shape}ä¸åŒ¹é…")
    
    return True

def preprocess_for_removal(images, masks):
    """é¢„å¤„ç†å›¾åƒå’Œè’™ç‰ˆç”¨äºå»é™¤"""
    out_images = []
    out_masks = []
    
    for img, msk in zip(images, masks):
        # æ ¹æ®é•¿å®½æ¯”è°ƒæ•´å°ºå¯¸
        if img.shape[0] > img.shape[1]:
            img_resized = cv2.resize(img, (480, 832), interpolation=cv2.INTER_LINEAR)
            msk_resized = cv2.resize(msk, (480, 832), interpolation=cv2.INTER_NEAREST)
        else:
            img_resized = cv2.resize(img, (832, 480), interpolation=cv2.INTER_LINEAR)
            msk_resized = cv2.resize(msk, (832, 480), interpolation=cv2.INTER_NEAREST)
        
        # å›¾åƒå½’ä¸€åŒ–åˆ°[-1, 1]
        img_resized = img_resized.astype(np.float32) / 127.5 - 1.0
        out_images.append(img_resized)
        
        # è’™ç‰ˆå½’ä¸€åŒ–åˆ°[0, 1]
        msk_resized = msk_resized.astype(np.float32)
        msk_resized = (msk_resized > 0.5).astype(np.float32)
        out_masks.append(msk_resized)
    
    arr_images = np.stack(out_images)
    arr_masks = np.stack(out_masks)
    
    return torch.from_numpy(arr_images).half().to(device), torch.from_numpy(arr_masks).half().to(device)

def remove_watermark(video_path, mask_path, max_frames, dilation_iterations, num_inference_steps, progress=gr.Progress()):
    """å»é™¤æ°´å°ä¸»å‡½æ•°"""
    if video_path is None:
        raise gr.Error("è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
    if mask_path is None:
        raise gr.Error("è¯·ä¸Šä¼ è’™ç‰ˆæ–‡ä»¶")
    
    progress(0.1, "åŠ è½½è§†é¢‘...")
    # åŠ è½½è§†é¢‘å¸§
    video_frames, num_frames = load_video_frames(video_path, max_frames)
    
    progress(0.2, "åŠ è½½è’™ç‰ˆ...")
    # åŠ è½½è’™ç‰ˆå¸§
    mask_frames = load_mask_frames(mask_path, num_frames)
    
    progress(0.3, "éªŒè¯å°ºå¯¸...")
    # éªŒè¯å°ºå¯¸
    validate_dimensions(video_frames, mask_frames)
    
    progress(0.4, "é¢„å¤„ç†æ•°æ®...")
    # é¢„å¤„ç†
    img_tensor, mask_tensor = preprocess_for_removal(video_frames, mask_frames)
    mask_tensor = mask_tensor[:,:,:,None]  # æ·»åŠ é€šé“ç»´åº¦
    
    # ç¡®å®šè¾“å‡ºå°ºå¯¸
    if mask_tensor.shape[1] < mask_tensor.shape[2]:
        height, width = 480, 832
    else:
        height, width = 832, 480
    
    progress(0.5, "å¼€å§‹å»é™¤æ°´å°...")
    # æ‰§è¡Œæ¨ç†
    with torch.no_grad():
        out = pipe(
            images=img_tensor,
            masks=mask_tensor,
            num_frames=mask_tensor.shape[0],
            height=height,
            width=width,
            num_inference_steps=int(num_inference_steps),
            generator=torch.Generator(device=device).manual_seed(random_seed),
            iterations=int(dilation_iterations)
        ).frames[0]
    
    progress(0.8, "ç”Ÿæˆè§†é¢‘...")
    # è½¬æ¢è¾“å‡ºæ ¼å¼
    out = np.uint8(out * 255)
    output_frames = [img for img in out]
    
    # ä¿å­˜è§†é¢‘
    video_file = f"/tmp/{time.time()}-{random.random()}-watermark_removed.mp4"
    clip = ImageSequenceClip(output_frames, fps=15)
    clip.write_videofile(video_file, codec='libx264', audio=False, verbose=False, logger=None)
    
    progress(1.0, "å®Œæˆ!")
    return video_file

def create_preview(video_path, mask_path):
    """åˆ›å»ºé¢„è§ˆå›¾ï¼Œæ˜¾ç¤ºç¬¬ä¸€å¸§å’Œè’™ç‰ˆå åŠ æ•ˆæœ"""
    if video_path is None or mask_path is None:
        return None
    
    try:
        # åŠ è½½ç¬¬ä¸€å¸§
        vr_video = VideoReader(video_path, ctx=cpu(0))
        first_frame = vr_video[0].asnumpy()
        del vr_video
        
        # åŠ è½½ç¬¬ä¸€ä¸ªè’™ç‰ˆ
        vr_mask = VideoReader(mask_path, ctx=cpu(0))
        first_mask = vr_mask[0].asnumpy()
        del vr_mask
        
        # è½¬æ¢è’™ç‰ˆä¸ºç°åº¦
        if len(first_mask.shape) == 3:
            first_mask = cv2.cvtColor(first_mask, cv2.COLOR_RGB2GRAY)
        
        # è°ƒæ•´è’™ç‰ˆå°ºå¯¸åŒ¹é…è§†é¢‘
        if first_frame.shape[:2] != first_mask.shape[:2]:
            first_mask = cv2.resize(first_mask, (first_frame.shape[1], first_frame.shape[0]))
        
        # åˆ›å»ºå åŠ æ•ˆæœ
        mask_normalized = (first_mask > 127).astype(np.float32)
        mask_colored = np.stack([mask_normalized * 255, np.zeros_like(mask_normalized), np.zeros_like(mask_normalized)], axis=-1)
        
        # å åŠ è’™ç‰ˆåˆ°å›¾åƒä¸Š
        overlay = first_frame.astype(np.float32) * 0.7 + mask_colored * 0.3
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        
        return Image.fromarray(overlay)
    except Exception as e:
        gr.Warning(f"é¢„è§ˆç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

# åˆå§‹åŒ–ç®¡é“
pipe = get_pipeline()

# HTMLæ ‡é¢˜
title_html = """
<div style='text-align:center; font-size:32px; font-family: Arial, Helvetica, sans-serif; margin-bottom: 20px;'>
  <span style="color:#2196f3;"><b>MiniMax</b></span><span style="color:#f06292;"><b>-Remover</b></span> æ°´å°å»é™¤å·¥å…·
</div>
<div style='text-align:center; font-size:16px; color: #666; margin-bottom: 30px;'>
  ä¸Šä¼ è§†é¢‘å’Œå¯¹åº”çš„è’™ç‰ˆæ–‡ä»¶ï¼Œè‡ªåŠ¨å»é™¤å›ºå®šä½ç½®çš„æ°´å°
</div>
"""

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="MiniMax-Remover æ°´å°å»é™¤å·¥å…·") as demo:
    gr.HTML(title_html)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
            video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶", height=300)
            mask_input = gr.Video(label="ä¸Šä¼ è’™ç‰ˆæ–‡ä»¶ (ä¸è§†é¢‘åŒå°ºå¯¸)", height=300)
            
            preview_btn = gr.Button("ğŸ” é¢„è§ˆå åŠ æ•ˆæœ", variant="secondary")
            preview_output = gr.Image(label="é¢„è§ˆ (çº¢è‰²åŒºåŸŸä¸ºæ°´å°ä½ç½®)", height=200)
            
        with gr.Column(scale=1):
            gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
            max_frames_slider = gr.Slider(
                minimum=10, maximum=201, value=81, step=1,
                label="æœ€å¤§å¤„ç†å¸§æ•°", 
                info="é™åˆ¶å¤„ç†çš„è§†é¢‘å¸§æ•°ï¼Œå‡å°‘å¤„ç†æ—¶é—´"
            )
            dilation_slider = gr.Slider(
                minimum=1, maximum=20, value=6, step=1,
                label="è’™ç‰ˆè†¨èƒ€è¿­ä»£æ¬¡æ•°", 
                info="å¢åŠ æ­¤å€¼å¯æ‰©å¤§å»é™¤åŒºåŸŸ"
            )
            inference_steps_slider = gr.Slider(
                minimum=1, maximum=50, value=6, step=1,
                label="æ¨ç†æ­¥æ•°", 
                info="å¢åŠ æ­¥æ•°å¯æé«˜è´¨é‡ä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´"
            )
            
            remove_btn = gr.Button("ğŸš€ å¼€å§‹å»é™¤æ°´å°", variant="primary", size="lg")
    
    with gr.Row():
        with gr.Column():
            output_video = gr.Video(label="å»æ°´å°ç»“æœ", height=400)
    
    with gr.Row():
        gr.Markdown("""
        ### ğŸ“‹ ä½¿ç”¨è¯´æ˜
        1. **ä¸Šä¼ è§†é¢‘æ–‡ä»¶**: é€‰æ‹©éœ€è¦å»é™¤æ°´å°çš„è§†é¢‘
        2. **ä¸Šä¼ è’™ç‰ˆæ–‡ä»¶**: ä¸Šä¼ ä¸è§†é¢‘åŒå°ºå¯¸çš„è’™ç‰ˆè§†é¢‘ï¼Œç™½è‰²åŒºåŸŸè¡¨ç¤ºæ°´å°ä½ç½®
        3. **é¢„è§ˆæ•ˆæœ**: ç‚¹å‡»é¢„è§ˆæŒ‰é’®æŸ¥çœ‹è’™ç‰ˆå åŠ æ•ˆæœ
        4. **è°ƒæ•´å‚æ•°**: æ ¹æ®éœ€è¦è°ƒæ•´å¤„ç†å‚æ•°
        5. **å¼€å§‹å¤„ç†**: ç‚¹å‡»"å¼€å§‹å»é™¤æ°´å°"æŒ‰é’®
        
        ### ğŸ’¡ æç¤º
        - è’™ç‰ˆæ–‡ä»¶å¿…é¡»ä¸è§†é¢‘æ–‡ä»¶å…·æœ‰ç›¸åŒçš„å°ºå¯¸å’Œå¸§æ•°
        - è’™ç‰ˆä¸­ç™½è‰²/äº®è‰²åŒºåŸŸè¡¨ç¤ºéœ€è¦å»é™¤çš„æ°´å°ä½ç½®
        - å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œå‚æ•°è®¾ç½®
        - å»ºè®®å…ˆç”¨è¾ƒå°‘å¸§æ•°æµ‹è¯•æ•ˆæœ
        """)
    
    # ç¤ºä¾‹æ–‡ä»¶
    gr.Examples(
        examples=[
            ["./normal_videos/0.mp4"],
            ["./normal_videos/1.mp4"],
            ["./cartoon/0.mp4"],
            ["./cartoon/1.mp4"],
        ],
        inputs=[video_input],
        label="ç¤ºä¾‹è§†é¢‘"
    )
    
    # äº‹ä»¶ç»‘å®š
    preview_btn.click(
        create_preview,
        inputs=[video_input, mask_input],
        outputs=preview_output
    )
    
    remove_btn.click(
        remove_watermark,
        inputs=[video_input, mask_input, max_frames_slider, dilation_slider, inference_steps_slider],
        outputs=output_video
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=8001, share=False)